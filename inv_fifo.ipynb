{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- select * from  dsc_dwd.dwd_wh_dsc_inventory_dtl_di \n",
    "-- where src = 'scale'\n",
    "-- and data_source in ('scale_hpi', 'scale_michelin', 'scale_fas', 'scale_bose')\n",
    "-- and inc_day in ('20211124', '20211117', '20211110', '20211103', \n",
    "-- '20211027', '20211020', '20211013','20211006')\n",
    "-- and usage_flag = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(os.listdir('data_down'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./data_down/inv_7.csv', sep='\\001')\n",
    "df.columns = [re.sub('\\w+\\.', '', i) for i in list(df.columns)]\n",
    "df = df.dropna(how = 'all', axis =1)\n",
    "time_cols = pd.Series(df.columns)[pd.Series(df.columns).str.lower().str.findall('date|time').apply(len)>0]\n",
    "df[time_cols] = df[time_cols].apply(lambda x: x.str.slice(0,10))\n",
    "df0 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_source):\n",
    "    \"\"\"\n",
    "    load bose data;\n",
    "    所有类型的qty都要加起来哦\n",
    "    只选择有多个收货日期的货物\n",
    "    \"\"\"\n",
    "    df = df0.copy()\n",
    "    df = df[df['data_source'] == data_source]\n",
    "    df ['recived_date'] = pd.to_datetime(df['recived_date'])\n",
    "    df = df[['wms_company_name', 'wms_warehouse_id','sku_code', 'sku_name', 'sku_desc', 'location_zone',\\\n",
    "        'lock_codes', 'on_hand_qty', 'in_transit_qty','allocated_qty', 'shelf_days', \n",
    "        'recived_date','usage_flag', 'inc_day']]\n",
    "    qty = pd.Series(df.columns).str.extract('(.+qty)').dropna(axis = 0)\n",
    "    df['qty'] = df[qty[0]].sum(axis = 1)\n",
    "    # bose_inv.drop_duplicates(subset = ['sku_code', 'recived_date', 'lock_codes', 'inc_day', 'qty'])\n",
    "    # 没有重复的 目前看....\n",
    "    df = df.groupby(['recived_date', 'sku_code', 'lock_codes','inc_day'], dropna = False).agg(\n",
    "    {\n",
    "        'qty':sum,\n",
    "        'location_zone': set\n",
    "    }\n",
    "    ).sort_values(['sku_code', 'recived_date']).reset_index()\n",
    "    # 只选择有多个收货日期的货物\n",
    "    filter0 = df.groupby(['sku_code'])['recived_date'].agg(\n",
    "    {\n",
    "        set\n",
    "    }\n",
    "        ).reset_index()\n",
    "\n",
    "    filter0 = pd.DataFrame(filter0[filter0['set'].apply(len)> 1]['sku_code'].drop_duplicates())\n",
    "    bose_inv = filter0.merge(df, on = ['sku_code'], how = 'inner')\\\n",
    "        .sort_values(['recived_date','sku_code', 'inc_day'])\n",
    "    \n",
    "    return bose_inv\n",
    "\n",
    "bose_inv = load_data('scale_bose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 只选择多次出库的货物\n",
    "# filter = bose.groupby(['recived_date', 'sku_code'])['inc_day'].agg({set}).reset_index()\n",
    "# filter = filter[filter['set'].apply(len)> 1][['recived_date','sku_code']].drop_duplicates();filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df0 = pd.DataFrame()\n",
    "def snapshot():\n",
    "    \"\"\"\n",
    "    pivot table. inc_day 快照 作为 cols\n",
    "    添加标记.\n",
    "    \"\"\"\n",
    "    global df0\n",
    "    for i in tqdm(bose_inv['sku_code'].unique(), ascii= False, colour = 'green'):\n",
    "        df_out = bose_inv[bose_inv['sku_code'] == i]\\\n",
    "            .pivot_table(columns=['inc_day'], index = 'recived_date', values=['qty']).reset_index()\n",
    "        df_out['sku_code'] = i\n",
    "        df0 = pd.concat([df0, df_out], axis = 0)\n",
    "    df0.columns = df0.columns.get_level_values(level=1)\n",
    "    df0.columns = list(df0.columns[0:8]) + ['received_date','sku']\n",
    "    df0 = df0.sort_values(['sku', 'received_date'])\n",
    "    df0['mark'] = 0\n",
    "    # 这个吊东`西不知道为什么是反选的 \n",
    "    df0['mark'] = df0['mark'].where(df0.iloc[:, 0:7].isna().all(axis = 1) == False, 'new')\n",
    "    df0['mark'] = df0['mark'].where(~df0.iloc[:,7].isna() , 'clear')\n",
    "snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_inv = bose_inv.rename({'sku_code':'sku', 'recived_date':'received_date'}, axis = 1)\\\n",
    "    .reset_index(drop = True).drop('inc_day', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df0.merge(bose_inv, on = ['sku','recived_date'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_part():\n",
    "    \"\"\"\n",
    "    findout who are the naught peach.\n",
    "    \"\"\"\n",
    "    df_err = df0[df0['mark'] != 'new']\n",
    "    # 补充可能被锁的标记\n",
    "    df_err['mark'] = df_err['mark'].where(df_err.iloc[:, 0:8].fillna(0).nunique(axis = 1) > 1, 'may_lock')\n",
    "    df_err = df_err[df_err['mark'] != 'may_lock'].sort_values(['sku', 'received_date'])\n",
    "    df_err['change'] = df_err.iloc[:,0:8].diff(axis = 1).sum(axis = 1)\n",
    "    shift = df_err.groupby('sku').shift(1) \n",
    "    # q = []\n",
    "    # for i in shift['mark']:\n",
    "    #     if pd.isna(i):\n",
    "    #         q.append('clear')\n",
    "    #     elif i =='clear':\n",
    "    #         q.append('clear')\n",
    "    #     else:\n",
    "    #         q.append('check')\n",
    "    # shift['mark'] = q\n",
    "    # shift['mark2'] = shift.iloc[:,0:8].diff(axis = 1).sum(axis = 1)\n",
    "    shift = shift[['mark','change']]\n",
    "    shift.columns = ['lag_mark', 'lag_change']\n",
    "    shift['lag_mark'] = shift['lag_mark'].where(~shift['lag_mark'].isna(), 'clear')\n",
    "    df_err = pd.concat([df_err, shift], axis = 1)\n",
    "    # df_wrong = df_err[(df_err['lag_mark'] != 'clear') & (df_err['change'] != 0)]\n",
    "    # df_good  = df_err[(df_err['lag_mark'] != 'clear') | (df_err['change'] != 0)]\n",
    "    return df_err\n",
    "df_err = err_part()\n",
    "    # shift['mark'] = ['clear' if (i == np.nan) 'clear'  elif (i =='clear') else 'check' for i in shift['mark']];shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[(df_err['lag_mark'] != 'clear') & (df_err['change'] != 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[(df_err['lag_mark'] == 'clear') & (df_err['change'] == 0)]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47b50d2908d96196e4220cfb4e81faa93803065ea975497e7026f672c1f58470"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('siming': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
